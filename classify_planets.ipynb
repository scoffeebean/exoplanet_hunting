{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b94c3bd-e4bb-4094-8060-a36332fa95ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exoplanet Hunting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84430c54-f537-49ba-b1e5-d54c6436bb8f",
   "metadata": {},
   "source": [
    "This is a classification task. The goal is to classify whether a given star has at least one exoplanet based on the star's flux (light intensity) data.\n",
    "\n",
    "Stars that exhibit regular \"dimming\" are candidates for having exoplanets. The \"dimming\" comes from when a star is partially obscured by a planet or object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7727028d-2277-45e6-9f93-05316a1a20a4",
   "metadata": {},
   "source": [
    "The data is retrieved from [Exoplanet Hunting in Deep Space](https://www.kaggle.com/datasets/keplersmachines/kepler-labelled-time-series-data?select=exoTest.csv) on Kaggle.\n",
    "\n",
    "Note: You will need to download and unzip the data into the data folder of this project should you want to run it yourself. There, you should have two files named exoTest.csv and exoTrain.csv. These are the default unzipped names from the download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d198ae37-df7c-46c3-8be3-f69c1c06a954",
   "metadata": {},
   "source": [
    "### Python and Initial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc02eb-41e0-45a4-a38c-32396541e170",
   "metadata": {},
   "source": [
    "Here we will run some initialization and setup steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd502bb4-cbfa-4e58-a04c-887489b3f25f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbd712f6-8f0b-4a27-8052-c8613d17d2b2",
   "metadata": {},
   "source": [
    "### Loading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9ef116-5af9-4f7b-86a2-f1472b74432d",
   "metadata": {},
   "source": [
    "Since the data is already broken up into test and train sets, we don't need to resample them. Since the data files themselves are large and numerical values, we can read them into numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338159c-6cf4-4b0d-9038-bb2d77fc6e76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
